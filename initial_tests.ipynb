{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Point of this notebook is simply to observe (withotu any decision making) the performance across a matrix of window skips and window lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: No IPv4 address found on anpi1 !\n",
      "WARNING: No IPv4 address found on anpi0 !\n",
      "WARNING: more No IPv4 address found on anpi2 !\n"
     ]
    }
   ],
   "source": [
    "from sampleddetection.common_lingo import Action, State\n",
    "from sampleddetection.environment.model import Environment\n",
    "from sampleddetection.datastructures.flowsession import SampledFlowSession\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "import random\n",
    "\n",
    "# Make sure these are reloaded when cells are rerun\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 9 permutaitions\n"
     ]
    }
   ],
   "source": [
    "# Setup the environment\n",
    "# From Microsecond to dekasecond\n",
    "window_skips    = 2*np.logspace(-6, 1, 3, dtype=float)\n",
    "window_lengths  = 2*np.logspace(-5, 1, 3, dtype=float)\n",
    "batch_size      = 16\n",
    "csv_path = './bigdata/Wednesday.csv'\n",
    "dataset_dir    = './bigdata/precalc_windows/'\n",
    "dataset_filename = 'ws_{}_wl_{}.csv'\n",
    "desired_features = [\n",
    "            # Debugging info\n",
    "            \"start_ts\",\n",
    "            \"start_timestamp\",\n",
    "            \"end_timestamp\",\n",
    "            \"tot_fwd_pkts\",\n",
    "            \"tot_bwd_pkts\",\n",
    "            # Non debugging\n",
    "            \"fwd_pkt_len_max\",\n",
    "            \"fwd_pkt_len_min\",\n",
    "            \"fwd_pkt_len_mean\",\n",
    "            \"bwd_pkt_len_max\",\n",
    "            \"bwd_pkt_len_min\",\n",
    "            \"bwd_pkt_len_mean\",\n",
    "            \"flow_byts_s\",\n",
    "            \"flow_pkts_s\",\n",
    "            \"flow_iat_mean\",\n",
    "            \"flow_iat_max\",\n",
    "            \"flow_iat_min\",\n",
    "            \"fwd_iat_mean\",\n",
    "            \"fwd_iat_max\",\n",
    "            \"fwd_iat_min\",\n",
    "            \"bwd_iat_max\",\n",
    "            \"bwd_iat_min\",\n",
    "            \"bwd_iat_mean\",\n",
    "            \"pkt_len_min\",\n",
    "            \"pkt_len_max\",\n",
    "            \"pkt_len_mean\",\n",
    "]\n",
    "\n",
    "# Use product to get a matrix of combinations\n",
    "options_matrix = list(product(window_skips, window_lengths))\n",
    "print(f\"Working with {len(options_matrix)} permutaitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 15:11:28,443 - DynamicWindowSampler - INFO - Loading the capture file bigdata/Wednesday.csv\n",
      "2024-03-26 15:11:28,444 - DynamicWindowSampler - INFO - Loading the capture file bigdata/Wednesday.csv\n",
      "2024-03-26 15:11:28,445 - CSVReader - INFO - Reading csv...\n",
      "2024-03-26 15:11:44,415 - CSVReader - INFO - CSV loaded, took  15.97 seconds with 13704955 length\n"
     ]
    }
   ],
   "source": [
    "# Create or Load dataset\n",
    "from sampleddetection.samplers.window_sampler import DynamicWindowSampler\n",
    "from sampleddetection.writers.convenience import save_to_csv\n",
    "from sampleddetection.readers.readers import CSVReader\n",
    "\n",
    "sampler = DynamicWindowSampler(Path(csv_path))\n",
    "environment = Environment(sampler)\n",
    "min_necessary_flows  = 10\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Create it\n",
    "\n",
    "    # Ensure that the dataset is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sessions(amount: int, ws: float, wl: float) -> List[SampledFlowSession]:\n",
    "    cur_amnt = 0\n",
    "    sessions = []\n",
    "    inner_bar = tqdm(total=amount,desc=f'Generating {ws}-{wl} flow',leave=False)\n",
    "    while cur_amnt < amount:\n",
    "        flow_sesh =  environment.reset(winskip=ws,winlen=wl).flow_sesh\n",
    "        amnt_sesh_flows = len(flow_sesh.flows.keys())\n",
    "        cur_amnt += amnt_sesh_flows\n",
    "        sessions.append(flow_sesh)\n",
    "\n",
    "        inner_bar.update(amnt_sesh_flows)\n",
    "    return sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f67dc8d53ea440182533d406a023dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating datasets:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f858ac8c3456436193ba336e2b7b5fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating 2e-06-2e-05 flow:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae52af286b734eff8a0eb549d0902d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating 2e-06-0.02 flow:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4be9adeb8be4a1d85db9c7d1bd1c0b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating 2e-06-20.0 flow:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11be13e7380a44c89e5a6efe52aba755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating 0.006324555320336759-2e-05 flow:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ddf21f64b2a415b95af498ab9b42e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating 0.006324555320336759-0.02 flow:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5963dc60e1b5493395e8d97f1c691998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating 0.006324555320336759-20.0 flow:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stoppy\n",
      "Stoppy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf985686b0f40ce95a9bcf8862caedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating 20.0-2e-05 flow:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8658bc91456b4dd0a4eb9d43afc6d9e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating 20.0-0.02 flow:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65cc3e41696447dfa9911dd9c542ce30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating 20.0-20.0 flow:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "flows = {}\n",
    "# Set random seeds:\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "import csv\n",
    "\n",
    "for ws, wl in tqdm(options_matrix,desc='Creating datasets'):\n",
    "    # Check if datasets exists\n",
    "    flows = {f\"ws:{ws}-ws:{wl}\" : []}\n",
    "    target_name = os.path.join(dataset_dir,dataset_filename.format(ws, wl))\n",
    "    if os.path.exists(target_name):\n",
    "        print(f\"Loading {dataset_filename.format(ws, wl)} from {dataset_dir}\")\n",
    "        with open(target_name) as f:\n",
    "            # Get csv lines into dictionary as a list\n",
    "            flows[f\"ws:{ws}-ws:{wl}\"] = [line for line in csv.DictReader(f)]\n",
    "        continue\n",
    "    sessions = generate_sessions(min_necessary_flows,ws,wl)\n",
    "\n",
    "    ds_path = os.path.join(dataset_dir,dataset_filename.format(ws, wl))\n",
    "    save_to_csv(sessions, ds_path, desired_features=desired_features, overwrite=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Stating time 2e-06 out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create the environment\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m wk,wl \u001b[38;5;129;01min\u001b[39;00m options_matrix:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# This will be a bit of a hack.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     state, _ \u001b[38;5;241m=\u001b[39m \u001b[43menvironment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Since we will be training our tree model on an per-observation basis, we can just use `environment.reset()` for our needs and foreget about `steps()`\u001b[39;00m\n",
      "File \u001b[0;32m~/Research/Polimi/SampledDetection/sampleddetection/environment/model.py:105\u001b[0m, in \u001b[0;36mEnvironment.reset\u001b[0;34m(self, starting_time, winskip, winlen)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     97\u001b[0m     starting_time: Union[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# Staring Frequencies\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# Create New Flow Session\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_triad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstarting_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwinskip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwinlen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     flow_sesh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler\u001b[38;5;241m.\u001b[39msample(\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarting_time,\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcur_winskip,\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcur_winlen,\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m State(\n\u001b[1;32m    114\u001b[0m         time_point\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarting_time,\n\u001b[1;32m    115\u001b[0m         window_skip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcur_winskip,\n\u001b[1;32m    116\u001b[0m         window_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcur_winlen,\n\u001b[1;32m    117\u001b[0m         flow_sesh\u001b[38;5;241m=\u001b[39mflow_sesh,\n\u001b[1;32m    118\u001b[0m     )\n",
      "File \u001b[0;32m~/Research/Polimi/SampledDetection/sampleddetection/environment/model.py:141\u001b[0m, in \u001b[0;36mEnvironment._initialize_triad\u001b[0;34m(self, starting_time, winskip, winlen)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarting_time \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39muniform(\n\u001b[1;32m    137\u001b[0m         min_time,\n\u001b[1;32m    138\u001b[0m         min_time \u001b[38;5;241m+\u001b[39m (max_time \u001b[38;5;241m-\u001b[39m min_time) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDAY_RIGHT_MARGIN,\n\u001b[1;32m    139\u001b[0m     )\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m within(\n\u001b[1;32m    142\u001b[0m         starting_time, min_time, max_time \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDAY_RIGHT_MARGIN\n\u001b[1;32m    143\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStating time \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstarting_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m out of range\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarting_time \u001b[38;5;241m=\u001b[39m starting_time\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Winskip\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Stating time 2e-06 out of range"
     ]
    }
   ],
   "source": [
    "# Create the environment\n",
    "for wk,wl in options_matrix:\n",
    "    # This will be a bit of a hack.\n",
    "    # Since we will be training our tree model on an per-observation basis, we can just use `environment.reset()` for our needs and foreget about `steps()`\n",
    "    state, _ = environment.reset(wk, wl)\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
