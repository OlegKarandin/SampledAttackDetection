{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Point of this notebook is simply to observe (withotu any decision making) the performance across a matrix of window skips and window lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sampleddetection.common_lingo import Action, State\n",
    "from sampleddetection.environment.model import Environment\n",
    "from sampleddetection.datastructures.flowsession import SampledFlowSession\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "import random\n",
    "\n",
    "# Make sure these are reloaded when cells are rerun\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the environment\n",
    "# From Microsecond to dekasecond\n",
    "window_skips    = 2*np.logspace(-6, 1, 3, dtype=float)\n",
    "window_lengths  = 2*np.logspace(-5, 1, 3, dtype=float)\n",
    "batch_size      = 16\n",
    "csv_path = './data/miniLabeledWednesday.csv'\n",
    "dataset_dir    = './data/precalc_windows/'\n",
    "dataset_filename = 'ws_{}_wl_{}.csv'\n",
    "desired_features = [\n",
    "            # Debugging info\n",
    "            \"start_ts\",\n",
    "            \"start_timestamp\",\n",
    "            \"end_timestamp\",\n",
    "            \"tot_fwd_pkts\",\n",
    "            \"tot_bwd_pkts\",\n",
    "            # Non debugging\n",
    "            \"label\",\n",
    "            \"fwd_pkt_len_max\",\n",
    "            \"fwd_pkt_len_min\",\n",
    "            \"fwd_pkt_len_mean\",\n",
    "            \"bwd_pkt_len_max\",\n",
    "            \"bwd_pkt_len_min\",\n",
    "            \"bwd_pkt_len_mean\",\n",
    "            \"flow_byts_s\",\n",
    "            \"flow_pkts_s\",\n",
    "            \"flow_iat_mean\",\n",
    "            \"flow_iat_max\",\n",
    "            \"flow_iat_min\",\n",
    "            \"fwd_iat_mean\",\n",
    "            \"fwd_iat_max\",\n",
    "            \"fwd_iat_min\",\n",
    "            \"bwd_iat_max\",\n",
    "            \"bwd_iat_min\",\n",
    "            \"bwd_iat_mean\",\n",
    "            \"pkt_len_min\",\n",
    "            \"pkt_len_max\",\n",
    "            \"pkt_len_mean\",\n",
    "]\n",
    "\n",
    "# Use product to get a matrix of combinations\n",
    "options_matrix = list(product(window_skips, window_lengths))\n",
    "print(f\"Working with {len(options_matrix)} permutaitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or Load dataset\n",
    "from sampleddetection.samplers.window_sampler import DynamicWindowSampler\n",
    "from sampleddetection.writers.convenience import save_to_csv\n",
    "from sampleddetection.readers.readers import CSVReader\n",
    "\n",
    "sampler = DynamicWindowSampler(Path(csv_path))\n",
    "environment = Environment(sampler)\n",
    "min_necessary_flows  = 20\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Create it\n",
    "\n",
    "    # Ensure that the dataset is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sessions(amount: int, ws: float, wl: float) -> List[SampledFlowSession]:\n",
    "    cur_amnt = 0\n",
    "    sessions = []\n",
    "    inner_bar = tqdm(total=amount,desc=f'Generating ws:{ws}- wl{wl} flow',leave=False)\n",
    "    while cur_amnt < amount:\n",
    "        flow_sesh =  environment.reset(winskip=ws,winlen=wl).flow_sesh\n",
    "        amnt_sesh_flows = len(flow_sesh.flows.keys())\n",
    "        cur_amnt += amnt_sesh_flows\n",
    "        sessions.append(flow_sesh)\n",
    "\n",
    "        inner_bar.update(amnt_sesh_flows)\n",
    "    return sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flows = {}\n",
    "# Set random seeds:\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "import csv\n",
    "\n",
    "for ws, wl in tqdm(options_matrix,desc='Creating datasets'):\n",
    "    # Check if datasets exists\n",
    "    flows = {f\"ws:{ws}-ws:{wl}\" : []}\n",
    "    target_name = os.path.join(dataset_dir,dataset_filename.format(ws, wl))\n",
    "    if os.path.exists(target_name):\n",
    "        print(f\"Loading {dataset_filename.format(ws, wl)} from {dataset_dir}\")\n",
    "        with open(target_name) as f:\n",
    "            # Get csv lines into dictionary as a list\n",
    "            flows[f\"ws:{ws}-ws:{wl}\"] = [line for line in csv.DictReader(f)]\n",
    "        continue\n",
    "    sessions = generate_sessions(min_necessary_flows,ws,wl)\n",
    "\n",
    "    ds_path = os.path.join(dataset_dir,dataset_filename.format(ws, wl))\n",
    "    save_to_csv(sessions, ds_path, desired_features=desired_features, overwrite=True)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
